ğŸ“„ Agentic Test Case Generator with Conversational Refinement
An interactive Streamlit-based application that transforms user stories and technical specifications into comprehensive test cases using LLMs. Users can upload PDFs, generate test cases, and refine them in real-time through natural language prompts.

ğŸš€ Features
ğŸ§  LLM-Powered Test Case Generation using LangGraph and Groqâ€™s LLaMA 3 API

ğŸ“„ Upload user stories and specifications as PDFs

ğŸ§ª Get structured test cases in a clean markdown table

ğŸ—£ï¸ Chat interface for refining and extending test cases via conversational feedback

ğŸ” Built-in API key management via sidebar

ğŸ” Maintains full traceability between requirements and test cases

ğŸ“‚ Project Structure
bash
Copy
Edit
.
â”œâ”€â”€ main.py          # Streamlit app frontend
â”œâ”€â”€ nodes.py         # Core logic for test generation and refinement
â”œâ”€â”€ graph.py         # LangGraph workflow definition
â”œâ”€â”€ state.py         # Shared state definition across graph steps
â””â”€â”€ README.md        # Project documentation
ğŸ“¸ Demo


Upload your documents â†’ View initial test cases â†’ Ask for refinements like:
â€œAdd a negative test for login failureâ€ or â€œInclude edge cases for file upload.â€

âš™ï¸ Requirements
Python 3.9+

Groq API key

PDF files containing user stories and specifications

ğŸ”§ Install dependencies
bash
Copy
Edit
pip install -r requirements.txt
If you don't have a requirements.txt yet, here's a starting point:

txt
Copy
Edit
streamlit
PyPDF2
langchain
langgraph
langchain-groq
ğŸ”‘ Set Up Groq API Key
Sign up at Groq Console

Copy your API key

Launch the app and paste your API key into the sidebar

â–¶ï¸ Running the App
bash
Copy
Edit
streamlit run main.py
ğŸ§  How It Works
This app uses a LangGraph workflow with the following steps:

generate_user_story_tests: Extracts test cases from user stories

generate_spec_tests: Extracts test cases from technical specs

merge_test_cases: Merges & deduplicates all cases

add_traceability: Adds traceability source info

refine_test_cases: Updates tests based on user feedback

ğŸ’¬ Sample User Prompts for Refinement
â€œAdd test cases for invalid email formatâ€

â€œCombine duplicate login testsâ€

â€œInclude performance edge casesâ€

ğŸ“ˆ Future Improvements
Export to CSV or Jira-compatible format

Multi-file PDF parsing

UI enhancements for previewing test tables

Support for other LLM providers (OpenAI, Claude, etc.)

